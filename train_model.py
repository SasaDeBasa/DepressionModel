# ----------------------------------------------------------
# ðŸ“Œ Imports
# ----------------------------------------------------------
import pandas as pd
import numpy as np
import joblib
import json

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report

# ----------------------------------------------------------
# ðŸ“Œ Load Data
# ----------------------------------------------------------
df = pd.read_csv('phq9_dataset.csv')
print("âœ… Data loaded.")

# ----------------------------------------------------------
# ðŸ“Œ Select relevant columns
# ----------------------------------------------------------
needed_cols = [
    'phq1','phq2','phq3','phq4','phq5','phq6','phq7','phq8','phq9',
    'age', 'sex', 'happiness.score', 'period.name'
]
df = df[needed_cols]
print("âœ… Columns selected:", list(df.columns))

# ----------------------------------------------------------
# ðŸ“Œ Drop rows with missing PHQ-9 items
# ----------------------------------------------------------
df = df.dropna(subset=['phq1','phq2','phq3','phq4','phq5','phq6','phq7','phq8','phq9'])
print(f"âœ… Rows remaining after PHQ drop: {df.shape[0]}")

# ----------------------------------------------------------
# ðŸ“Œ Fill missing age
# ----------------------------------------------------------
df['age'] = df['age'].fillna(df['age'].median())

# ----------------------------------------------------------
# ðŸ“Œ Clean 'sex' column
# ----------------------------------------------------------
df['sex'] = df['sex'].str.lower().replace({
    'm': 'male', 'f': 'female'
})
df['sex'] = df['sex'].where(df['sex'].isin(['male','female']), 'non-binary')
df['sex'] = df['sex'].fillna('non-binary')

print(f"âœ… 'sex' column standardized. Unique values: {df['sex'].unique()}")

# ----------------------------------------------------------
# ðŸ“Œ Create Depression Risk target
# ----------------------------------------------------------
df['phq_sum'] = df[['phq1','phq2','phq3','phq4','phq5','phq6','phq7','phq8','phq9']].sum(axis=1)
df['Depression_Risk'] = (df['phq_sum'] >= 10).astype(int)

print(df[['phq_sum','Depression_Risk']].head())

# ----------------------------------------------------------
# ðŸ“Œ Define features and target
# ----------------------------------------------------------
features = [
    'phq1','phq2','phq3','phq4','phq5','phq6','phq7','phq8','phq9',
    'age', 'sex', 'happiness.score', 'period.name'
]
X = df[features]
y = df['Depression_Risk']

# ----------------------------------------------------------
# ðŸ“Œ Split train/test
# ----------------------------------------------------------
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)
print("âœ… Split complete:", X_train.shape, X_test.shape)

# ----------------------------------------------------------
# ðŸ“Œ Define preprocessing
# ----------------------------------------------------------
numeric_features = [
    'phq1','phq2','phq3','phq4','phq5','phq6','phq7','phq8','phq9',
    'age', 'happiness.score'
]
categorical_features = ['sex', 'period.name']

preprocessor = ColumnTransformer([
    ('num', StandardScaler(), numeric_features),
    ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)
])

# ----------------------------------------------------------
# ðŸ“Œ Build pipeline
# ----------------------------------------------------------
pipeline = Pipeline([
    ('preprocessor', preprocessor),
    ('classifier', RandomForestClassifier(random_state=42))
])

print("âœ… Pipeline created.")

# ----------------------------------------------------------
# ðŸ“Œ Train model
# ----------------------------------------------------------
pipeline.fit(X_train, y_train)
print("âœ… Model trained!")

# ----------------------------------------------------------
# ðŸ“Œ Evaluate model
# ----------------------------------------------------------
y_pred = pipeline.predict(X_test)
print("âœ… Classification Report:\n")
print(classification_report(y_test, y_pred))

# ----------------------------------------------------------
# ðŸ“Œ Save trained model
# ----------------------------------------------------------
joblib.dump(pipeline, 'depression_model.pkl')
print("âœ… Model saved as depression_model.pkl")

# ----------------------------------------------------------
# ðŸ“Œ Save feature order for deployment
# ----------------------------------------------------------
feature_names = pipeline.named_steps['preprocessor'].get_feature_names_out().tolist()

with open('feature_order.json', 'w') as f:
    json.dump(feature_names, f)

print("âœ… Feature order saved as feature_order.json")
